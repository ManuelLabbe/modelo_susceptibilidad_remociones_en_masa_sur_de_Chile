{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from util import comparar_columnas, eliminar_caracteristicas, prueba_umbral\n",
    "from feature_selection import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['n_5-15cm', 'Bulkd.5-15cm', 'n_100-200cm', 'Tex_Class.100-200cm', 'theta_s_0-5cm', 'theta_s_15-30cm'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_dataframe.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPP\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_5-15cm\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslope\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalor_humedad_suelo1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[43mfinal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['n_5-15cm', 'Bulkd.5-15cm', 'n_100-200cm', 'Tex_Class.100-200cm', 'theta_s_0-5cm', 'theta_s_15-30cm'] not in index\""
     ]
    }
   ],
   "source": [
    "final = pd.read_csv('final_dataframe.csv', index_col=False)\n",
    "selected_features = ['PP',\n",
    "'n_5-15cm',\n",
    "'slope',\n",
    "'Bulkd.5-15cm',\n",
    "'n_100-200cm',\n",
    "'Tex_Class.100-200cm',\n",
    "'theta_s_0-5cm',\n",
    "'theta_s_15-30cm',\n",
    "'valor_humedad_suelo1',\n",
    "'Valor']\n",
    "final = final[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "def entrenar_y_guardar_modelos(df, columna_objetivo, ruta_guardado):\n",
    "    # Separar características y variable objetivo\n",
    "    X = df.drop(columns=[columna_objetivo])\n",
    "    y = df[columna_objetivo]\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Definir los modelos y sus hiperparámetros para GridSearchCV\n",
    "    modelos = {\n",
    "        'RandomForest': {\n",
    "            'modelo': RandomForestClassifier(random_state=42),\n",
    "            'parametros': {\n",
    "                'classifier__n_estimators': [100, 200, 300, 500],\n",
    "                'classifier__max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "                'classifier__min_samples_split': [2, 5, 10, 15, 20],\n",
    "                'classifier__min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "                'classifier__max_features': ['sqrt', 'log2', None],\n",
    "                'classifier__bootstrap': [True, False],\n",
    "                'classifier__random_state': [42],\n",
    "                'classifier__max_leaf_nodes': [None, 50, 100, 200],\n",
    "                'classifier__min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "                'classifier__min_impurity_decrease': [0.0, 0.01, 0.05],\n",
    "                'classifier__n_jobs': [-1]\n",
    "            }\n",
    "        },\n",
    "        'SVC': {\n",
    "            'modelo': SVC(probability=True, random_state=42),\n",
    "            'parametros': {\n",
    "                'classifier__C': [0.1, 1, 2, 10, 100],\n",
    "                'classifier__kernel': ['rbf'],\n",
    "                'classifier__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10, 20, 30, 50, 100],\n",
    "                'classifier__random_state': [42]\n",
    "            }\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'modelo': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "            'parametros': {\n",
    "                # Parámetros de estructura del árbol\n",
    "                'classifier__max_depth': [3, 5, 7, 9, 11],\n",
    "                'classifier__min_child_weight': [1, 3, 5, 7],\n",
    "                'classifier__gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "                \n",
    "                # Parámetros de regulación\n",
    "                'classifier__learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "                'classifier__n_estimators': [100, 200, 300, 500],\n",
    "                \n",
    "                # Parámetros de regularización\n",
    "                'classifier__reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "                'classifier__reg_lambda': [0.1, 0.5, 1.0, 2.0],\n",
    "                \n",
    "                \n",
    "                # Otros parámetros\n",
    "                'classifier__random_state': [42]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    metricas = {}\n",
    "    \n",
    "    for nombre, item in modelos.items():\n",
    "        modelo = item['modelo']\n",
    "        parametros = item['parametros']\n",
    "        \n",
    "        # Crear un Pipeline que incluye el escalado y el modelo\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', modelo)\n",
    "        ])\n",
    "        \n",
    "        # Realizar la búsqueda de hiperparámetros\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=parametros,\n",
    "            cv=3,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        mejor_modelo = grid.best_estimator_\n",
    "        \n",
    "        # Guardar el mejor modelo en un archivo .pkl\n",
    "        nombre_archivo_modelo = os.path.join(ruta_guardado, f\"{nombre}_mejor_modelo.pkl\")\n",
    "        joblib.dump(mejor_modelo, nombre_archivo_modelo)\n",
    "        \n",
    "        # Predecir en el conjunto de prueba\n",
    "        y_pred = mejor_modelo.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sensibilidad = tp / (tp + fn)  # Recall\n",
    "        especificidad = tn / (tn + fp)  # Specificity\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        exactitud = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        metricas[nombre] = {\n",
    "            'Sensibilidad': sensibilidad,\n",
    "            'Especificidad': especificidad,\n",
    "            'Precisión': precision,\n",
    "            'Exactitud': exactitud,\n",
    "            'Mejores Hiperparámetros': grid.best_params_\n",
    "        }\n",
    "        \n",
    "        # Añadir los nombres de las características al modelo\n",
    "        mejor_modelo.named_steps['classifier'].feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Guardar las métricas en un archivo .txt\n",
    "    nombre_archivo_metricas = os.path.join(ruta_guardado, 'metricas_modelos.txt')\n",
    "    with open(nombre_archivo_metricas, 'w') as file:\n",
    "        json.dump(metricas, file, indent=4)\n",
    "    \n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 151200 candidates, totalling 453600 fits\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Fitting 3 folds for each of 32000 candidates, totalling 96000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivo\\.conda\\envs\\geotiff\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [07:06:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'Sensibilidad': 0.8559498956158664,\n",
       "  'Especificidad': 0.8068669527896996,\n",
       "  'Precisión': 0.82,\n",
       "  'Exactitud': 0.8317460317460318,\n",
       "  'Mejores Hiperparámetros': {'classifier__bootstrap': True,\n",
       "   'classifier__max_depth': 15,\n",
       "   'classifier__max_features': None,\n",
       "   'classifier__max_leaf_nodes': 200,\n",
       "   'classifier__min_impurity_decrease': 0.0,\n",
       "   'classifier__min_samples_leaf': 1,\n",
       "   'classifier__min_samples_split': 5,\n",
       "   'classifier__min_weight_fraction_leaf': 0.0,\n",
       "   'classifier__n_estimators': 500,\n",
       "   'classifier__n_jobs': -1,\n",
       "   'classifier__random_state': 42}},\n",
       " 'SVC': {'Sensibilidad': 0.7933194154488518,\n",
       "  'Especificidad': 0.7532188841201717,\n",
       "  'Precisión': 0.7676767676767676,\n",
       "  'Exactitud': 0.7735449735449735,\n",
       "  'Mejores Hiperparámetros': {'classifier__C': 2,\n",
       "   'classifier__gamma': 0.1,\n",
       "   'classifier__kernel': 'rbf',\n",
       "   'classifier__random_state': 42}},\n",
       " 'XGBoost': {'Sensibilidad': 0.8830897703549061,\n",
       "  'Especificidad': 0.8347639484978541,\n",
       "  'Precisión': 0.846,\n",
       "  'Exactitud': 0.8592592592592593,\n",
       "  'Mejores Hiperparámetros': {'classifier__gamma': 0,\n",
       "   'classifier__learning_rate': 0.15,\n",
       "   'classifier__max_depth': 5,\n",
       "   'classifier__min_child_weight': 1,\n",
       "   'classifier__n_estimators': 300,\n",
       "   'classifier__random_state': 42,\n",
       "   'classifier__reg_alpha': 0.5,\n",
       "   'classifier__reg_lambda': 1.0}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'Valor'\n",
    "path_guardar = 'resultados_ga\\ga_xgboost_mutflip_0_5_mutprob_0_3_cpx_0_8'\n",
    "entrenar_y_guardar_modelos(final, target, path_guardar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: [0.2 0.  0.2 ... 0.4 0.2 0.8]\n",
      "Muestras no deslizamiento seleccionadas:\n",
      "      PIRange_Bulkd.0-5cm.tif  PIRange_Bulkd.100-200cm.tif  \\\n",
      "0                       0.609                        0.689   \n",
      "1                       0.609                        0.689   \n",
      "2                       0.595                        0.753   \n",
      "3                       0.589                        0.682   \n",
      "4                       0.659                        0.689   \n",
      "...                       ...                          ...   \n",
      "1820                    0.588                        0.687   \n",
      "1821                    0.594                        0.684   \n",
      "1822                    0.625                        0.690   \n",
      "1823                    0.593                        0.691   \n",
      "1824                    0.592                        0.702   \n",
      "\n",
      "      PIRange_Bulkd.15-30cm.tif  PIRange_Bulkd.30-60cm.tif  \\\n",
      "0                         0.483                      0.641   \n",
      "1                         0.483                      0.641   \n",
      "2                         0.484                      0.621   \n",
      "3                         0.482                      0.614   \n",
      "4                         0.573                      0.675   \n",
      "...                         ...                        ...   \n",
      "1820                      0.479                      0.613   \n",
      "1821                      0.485                      0.616   \n",
      "1822                      0.522                      0.648   \n",
      "1823                      0.484                      0.622   \n",
      "1824                      0.484                      0.617   \n",
      "\n",
      "      PIRange_Bulkd.5-15cm.tif  PIRange_Bulkd.60-100cm.tif  \\\n",
      "0                        0.550                       0.650   \n",
      "1                        0.550                       0.650   \n",
      "2                        0.497                       0.706   \n",
      "3                        0.498                       0.656   \n",
      "4                        0.553                       0.660   \n",
      "...                        ...                         ...   \n",
      "1820                     0.510                       0.644   \n",
      "1821                     0.517                       0.642   \n",
      "1822                     0.627                       0.658   \n",
      "1823                     0.678                       0.657   \n",
      "1824                     0.510                       0.669   \n",
      "\n",
      "      PIRange_Clay.0-5cm.tif  PIRange_Clay.100-200cm.tif  \\\n",
      "0                  22.358000                   32.235001   \n",
      "1                  22.358000                   32.235001   \n",
      "2                  23.513000                   32.325001   \n",
      "3                  25.056000                   45.129002   \n",
      "4                  21.844999                   30.417000   \n",
      "...                      ...                         ...   \n",
      "1820               26.491001                   45.632999   \n",
      "1821               28.490000                   47.789001   \n",
      "1822               24.723999                   43.557999   \n",
      "1823               25.836998                   44.098999   \n",
      "1824               28.064001                   45.316002   \n",
      "\n",
      "      PIRange_Clay.15-30cm.tif  PIRange_Clay.30-60cm.tif  ...  \\\n",
      "0                    22.490000                 26.009001  ...   \n",
      "1                    22.490000                 26.009001  ...   \n",
      "2                    25.268002                 31.559998  ...   \n",
      "3                    25.813000                 32.742996  ...   \n",
      "4                    18.743000                 21.934999  ...   \n",
      "...                        ...                       ...  ...   \n",
      "1820                 25.082001                 31.809002  ...   \n",
      "1821                 24.950001                 31.700001  ...   \n",
      "1822                 25.712999                 32.057999  ...   \n",
      "1823                 26.760998                 33.229000  ...   \n",
      "1824                 27.098000                 33.653000  ...   \n",
      "\n",
      "      Silt.60-100cm.tif  Tex_Class.0-5cm.tif  Tex_Class.100-200cm.tif  \\\n",
      "0             11.029000                  8.0                      8.0   \n",
      "1             11.029000                  8.0                      8.0   \n",
      "2             19.920000                  8.0                      8.0   \n",
      "3             35.306999                 10.0                      1.0   \n",
      "4             13.550000                  8.0                      4.0   \n",
      "...                 ...                  ...                      ...   \n",
      "1820          41.796001                  3.0                      2.0   \n",
      "1821          35.981998                  3.0                      3.0   \n",
      "1822          26.402000                  3.0                      3.0   \n",
      "1823          37.973000                  3.0                      3.0   \n",
      "1824          28.058001                  7.0                      7.0   \n",
      "\n",
      "      Tex_Class.15-30cm.tif  Tex_Class.30-60cm.tif  Tex_Class.5-15cm.tif  \\\n",
      "0                       8.0                    8.0                   4.0   \n",
      "1                       8.0                    8.0                   4.0   \n",
      "2                       7.0                    7.0                   7.0   \n",
      "3                       9.0                    1.0                   1.0   \n",
      "4                       8.0                    8.0                   8.0   \n",
      "...                     ...                    ...                   ...   \n",
      "1820                    3.0                    3.0                   2.0   \n",
      "1821                    3.0                    3.0                   2.0   \n",
      "1822                    3.0                    2.0                   7.0   \n",
      "1823                    2.0                    2.0                   3.0   \n",
      "1824                    3.0                    3.0                   2.0   \n",
      "\n",
      "      Tex_Class.60-100cm.tif          PP  valor_humedad_suelo1      slope  \n",
      "0                        8.0   13.532034              0.421875  32.357300  \n",
      "1                        8.0  238.139918              0.438995  32.357300  \n",
      "2                        7.0   32.059045              0.520004  37.497812  \n",
      "3                        1.0    0.000000              0.478973  36.717389  \n",
      "4                        4.0    2.191190              0.438095  60.517945  \n",
      "...                      ...         ...                   ...        ...  \n",
      "1820                     3.0    0.674241              0.416611  24.327043  \n",
      "1821                     3.0    1.054908              0.313675  24.641348  \n",
      "1822                     2.0    1.167900              0.352768  45.373746  \n",
      "1823                     2.0    0.000000              0.306458  35.755171  \n",
      "1824                     3.0    0.000000              0.335510  40.502730  \n",
      "\n",
      "[1317 rows x 136 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivo\\AppData\\Local\\Temp\\ipykernel_14580\\4043113540.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_non_landslide_samples['Valor'] = 0\n"
     ]
    }
   ],
   "source": [
    "from pubagging import PUBagging\n",
    "\n",
    "data = final\n",
    "data['Valor'] = final.Valor\n",
    "data_aux_1 = data[data.Valor == 1]\n",
    "data_aux_0 = data[data.Valor == 0]\n",
    "data_aux_0 = data_aux_0.drop(columns='Valor')\n",
    "data_aux_1 = data_aux_1.drop(columns='Valor')\n",
    "\n",
    "landslide_samples = data_aux_1# Example landslide samples as DataFrame\n",
    "unlabeled_samples = data_aux_0# Example unlabeled samples as DataFrame\n",
    "\n",
    "pu_bagging = PUBagging(num_iterations=5, sample_ratio=0.4, random_state=42)\n",
    "\n",
    "pu_bagging.fit(landslide_samples, unlabeled_samples)\n",
    "\n",
    "probabilities = pu_bagging.predict_proba(unlabeled_samples)\n",
    "print(\"Predicted probabilities:\", probabilities)\n",
    "\n",
    "threshold = 0.5 \n",
    "\n",
    "# Filtrar muestras no deslizamiento por debajo del umbral\n",
    "non_landslide_indices = np.where(probabilities < threshold)[0]\n",
    "selected_non_landslide_samples = unlabeled_samples.iloc[non_landslide_indices]\n",
    "\n",
    "# Ejemplo de cómo podrías utilizar las muestras seleccionadas\n",
    "print(\"Muestras no deslizamiento seleccionadas:\")\n",
    "print(selected_non_landslide_samples)\n",
    "\n",
    "# Se crean los nuevos dataframe para el reentreno donde tenemos data y data_y como input y output respectivamente\n",
    "selected_non_landslide_samples['Valor'] = 0\n",
    "data_aux_1['Valor'] = 1\n",
    "\n",
    "data = pd.concat([data_aux_1, selected_non_landslide_samples])\n",
    "data_y = data['Valor']\n",
    "#data = data.drop(columns=['Valor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 151200 candidates, totalling 453600 fits\n"
     ]
    }
   ],
   "source": [
    "path_guardar = 'resultados_ga\\ga_xgboost_mutflip_0_5_mutprob_0_3_cpx_0_8\\pubagging'\n",
    "entrenar_y_guardar_modelos(data, target, path_guardar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.9397 +- 0.0159\n",
      "Recall: 0.9770 +- 0.0128\n",
      "{'Exactitud': 0.9396825396825397, 'Exactitud Intervalo': (0.9238095238095239, 0.9555555555555556), 'Recall': 0.9770354906054279, 'Recall Intervalo': (0.9622621690185508, 0.9879281714382682)}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def evaluar_modelo(ruta_modelo, X_test, y_test, n_bootstrap=1000, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo guardado en un archivo .pkl y calcula su exactitud y recall con intervalos de confianza.\n",
    "\n",
    "    :param ruta_modelo: Ruta del archivo .pkl del modelo\n",
    "    :param X_test: Características de prueba\n",
    "    :param y_test: Etiquetas de prueba\n",
    "    :param n_bootstrap: Número de muestras bootstrap para calcular el intervalo de confianza\n",
    "    :param alpha: Nivel de confianza para el intervalo (por defecto 0.95)\n",
    "    :return: Diccionario con exactitud, recall y sus intervalos de confianza\n",
    "    \"\"\"\n",
    "    # Cargar el modelo\n",
    "    modelo = joblib.load(ruta_modelo)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Bootstrap para intervalos de confianza\n",
    "    exactitud_bootstrap = []\n",
    "    recall_bootstrap = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        X_resampled, y_resampled = resample(X_test, y_test)\n",
    "        y_pred_resampled = modelo.predict(X_resampled)\n",
    "        exactitud_bootstrap.append(accuracy_score(y_resampled, y_pred_resampled))\n",
    "        recall_bootstrap.append(recall_score(y_resampled, y_pred_resampled))\n",
    "    \n",
    "    # Calcular percentiles para el intervalo de confianza\n",
    "    lower_bound = (1.0 - alpha) / 2.0\n",
    "    upper_bound = 1.0 - lower_bound\n",
    "    \n",
    "    exactitud_intervalo = (np.percentile(exactitud_bootstrap, lower_bound * 100), \n",
    "                           np.percentile(exactitud_bootstrap, upper_bound * 100))\n",
    "    recall_intervalo = (np.percentile(recall_bootstrap, lower_bound * 100), \n",
    "                        np.percentile(recall_bootstrap, upper_bound * 100))\n",
    "    exactitud_error = (exactitud_intervalo[1] - exactitud_intervalo[0]) / 2\n",
    "    recall_error = (recall_intervalo[1] - recall_intervalo[0]) / 2\n",
    "    resultados = {\n",
    "        'Exactitud': exactitud,\n",
    "        'Exactitud Intervalo': exactitud_intervalo,\n",
    "        'Recall': recall,\n",
    "        'Recall Intervalo': recall_intervalo\n",
    "    }\n",
    "    print(f\"Exactitud: {exactitud:.4f} +- {exactitud_error:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f} +- {recall_error:.4f}\")\n",
    "    return resultados\n",
    "\n",
    "# Ejemplo de uso\n",
    "ruta_modelo = 'resultados_ga\\ga_randomforest_mutflip_0_3_mutprob_0_3_cpx_0_6\\pubagging\\RandomForest_mejor_modelo.pkl'\n",
    "X = final.drop(columns=[target])\n",
    "y = final[target]\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "resultados = evaluar_modelo(ruta_modelo, X_test, y_test)\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
