{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from util import comparar_columnas, eliminar_caracteristicas, prueba_umbral\n",
    "from feature_selection import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('final_dataframe.csv', index_col=False)\n",
    "selected_features = ['ksat_0-5cm.tif',\n",
    "'PP',\n",
    "'PWP.100-200cm.tif',\n",
    "'slope',\n",
    "'Bulkd.5-15cm.tif',\n",
    "'valor_humedad_suelo1',\n",
    "'Valor']\n",
    "final = final[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "def entrenar_y_guardar_modelos(df, columna_objetivo, ruta_guardado):\n",
    "    # Separar características y variable objetivo\n",
    "    X = df.drop(columns=[columna_objetivo])\n",
    "    y = df[columna_objetivo]\n",
    "    \n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Definir los modelos y sus hiperparámetros para GridSearchCV\n",
    "    modelos = {\n",
    "        'RandomForest': {\n",
    "            'modelo': RandomForestClassifier(random_state=42),\n",
    "            'parametros': {\n",
    "                'classifier__n_estimators': [100, 200, 300, 500],\n",
    "                'classifier__max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "                'classifier__min_samples_split': [2, 5, 10, 15, 20],\n",
    "                'classifier__min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "                'classifier__max_features': ['sqrt', 'log2', None],\n",
    "                'classifier__bootstrap': [True, False],\n",
    "                'classifier__random_state': [42],\n",
    "                'classifier__max_leaf_nodes': [None, 50, 100, 200],\n",
    "                'classifier__min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "                'classifier__min_impurity_decrease': [0.0, 0.01, 0.05],\n",
    "                'classifier__n_jobs': [-1]\n",
    "            }\n",
    "        },\n",
    "        'SVC': {\n",
    "            'modelo': SVC(probability=True, random_state=42),\n",
    "            'parametros': {\n",
    "                'classifier__C': [0.1, 1, 2, 10, 100],\n",
    "                'classifier__kernel': ['rbf'],\n",
    "                'classifier__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10, 20, 30, 50, 100],\n",
    "                'classifier__random_state': [42]\n",
    "            }\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'modelo': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "            'parametros': {\n",
    "                'classifier__max_depth': [3, 5, 7, 9, 11, 13],\n",
    "                'classifier__min_child_weight': [1, 3, 5, 7],\n",
    "                'classifier__gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "                'classifier__learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "                'classifier__n_estimators': [100, 200, 300, 500],\n",
    "                'classifier__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                'classifier__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                'classifier__reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "                'classifier__reg_lambda': [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "                'classifier__scale_pos_weight': [1, 3, 5],\n",
    "                'classifier__random_state': [42]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    metricas = {}\n",
    "    \n",
    "    for nombre, item in modelos.items():\n",
    "        modelo = item['modelo']\n",
    "        parametros = item['parametros']\n",
    "        \n",
    "        # Crear un Pipeline que incluye el escalado y el modelo\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', modelo)\n",
    "        ])\n",
    "        \n",
    "        # Realizar la búsqueda de hiperparámetros\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=parametros,\n",
    "            cv=3,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        mejor_modelo = grid.best_estimator_\n",
    "        \n",
    "        # Guardar el mejor modelo en un archivo .pkl\n",
    "        nombre_archivo_modelo = os.path.join(ruta_guardado, f\"{nombre}_mejor_modelo.pkl\")\n",
    "        joblib.dump(mejor_modelo, nombre_archivo_modelo)\n",
    "        \n",
    "        # Predecir en el conjunto de prueba\n",
    "        y_pred = mejor_modelo.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sensibilidad = tp / (tp + fn)  # Recall\n",
    "        especificidad = tn / (tn + fp)  # Specificity\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        exactitud = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        metricas[nombre] = {\n",
    "            'Sensibilidad': sensibilidad,\n",
    "            'Especificidad': especificidad,\n",
    "            'Precisión': precision,\n",
    "            'Exactitud': exactitud,\n",
    "            'Mejores Hiperparámetros': grid.best_params_\n",
    "        }\n",
    "        \n",
    "        # Añadir los nombres de las características al modelo\n",
    "        mejor_modelo.named_steps['classifier'].feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Guardar las métricas en un archivo .txt\n",
    "    nombre_archivo_metricas = os.path.join(ruta_guardado, 'metricas_modelos.txt')\n",
    "    with open(nombre_archivo_metricas, 'w') as file:\n",
    "        json.dump(metricas, file, indent=4)\n",
    "    \n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 151200 candidates, totalling 453600 fits\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Fitting 3 folds for each of 3600000 candidates, totalling 10800000 fits\n"
     ]
    }
   ],
   "source": [
    "target = 'Valor'\n",
    "path_guardar = 'resultados_ga\\ga_randomforest_mutflip_0_3_mutprob_0_3_cpx_0_6'\n",
    "entrenar_y_guardar_modelos(final, target, path_guardar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
